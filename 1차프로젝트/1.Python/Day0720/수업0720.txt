0720 수업 내용

1. anaconda 설치 
: python 기본 toolkit + 외부 라이브러리 
: 관리자 권한으로 실행
: path 우선 순위 변경 

2. EDitor - jupyter notebook
: Command line interface(CLI) : Python idle >>>
: ipython 을 기반으로 해서 브라우저상에서 사용하는 에디터 
: 크롬을 기본 브라우저로 설정해야

1. pandas : table data(표데이터) 처리
데이터 분석, db에 저장 , 시각화 연동
https://dataitgirls2.github.io/10minutes2pandas/
2. requests :  http client(통신)
https://requests.readthedocs.io/en/master/ 
3. beatifulsoup : html, xml 데이터 parsing(뽑아내)
https://www.crummy.com/software/BeautifulSoup/bs4/doc/ 
4. matplotlib : visualization(시각화), 폰트 , 막대그래프...  
https://pypi.org/project/matplotlib/
5. seaborn : visualization(시각화)
https://github.com/mwaskom/seaborn
https://seaborn.pydata.org/index.html#seaborn-statistical-data-visualization
6. pymysql : mysql db connector
https://github.com/PyMySQL/PyMySQL/
7. pymongo
https://github.com/mongodb/mongo-python-driver

8. sqlalchemy :  
ORM(Object Relation Mapping) 
Sql 에서만 쓰임
Tablular data : dataframe 객체
이걸 쓰면 자동으로 rdb 매핑, 객체만 만들면 됨, 속성 등등 이런거 미리 안해도 됨	`
Orm rule
Class <=> table
Object <=> row(record) 행 , 우리는 표데이터만 만들면 됨
Variable <=> column 백넘버, 선수 이름, 선수 키………..

9. jupyter notebook/ jupyter lab
https://jupyter-notebook.readthedocs.io/en/stable/
https://pypi.org/ 원하는 오픈소스 다운 
https://requests.readthedocs.io/en/master/ requests http
https://www.crummy.com/software/BeautifulSoup/bs4/doc/ beautifulsoup

오늘은 requests, beatifulsoup
월 14-15, 화16-17 책 읽기


181페이지
Pickle : 통신 같은거 할때 객체를 파일로 저장하고 다시 불러올 때 사용 가능
   Dump : 저장
   Load : 불러오기

*******************
Parising : 구문
1. 정규표현식(regular expression) 사용
2. beautifulsoup 사용 
주로 2번 사용// 1번이 어려움// 가끔 1번 사용

Version --python
path
Pip show beautifulsoup4
Pip show 


***************************

*******주피터 노트북 띄우기
C:\Users\yujin> cd C:\Python\webscrap_source    
>>Jupyter notebook - 내가 하고자 하는 파일 바로 나와
