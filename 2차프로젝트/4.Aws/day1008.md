## 복습

- 어제 한 첫번째 실습 : 원격 아이피 설정 권한이 없어서 인터넷이 안된것이없음
- 어제 두번째(워크스테이션 만들기) : EC2 워크스테이션(AWS CLI로 AWS 인스턴스를 생성, 관리할 권한을 가진 인스턴스)를 생성한 후 DynamoDB, S3, SNS 등의 AWS 인스턴스를 사용
- 어제 세번째(custom ami): 러닝 타임 줄이기 위해 서비스 가능한 어플리케이션 설치된 것을 이미지로 만들고, 인스턴스로 만들고 이것으로 환경 구축, 동일 리전에서만 가능하다, 별도의 리전에서 인스턴스 만들려면 ami 복사해서 인스턴스 생성하는 것은 가능
- 어제 네번째(ebs 볼륨 바꾸기): 오토스케일링이랑 스탠드어론?? 지금돌고 있는 것의 스냅샷 뜨고 볼륨 바꾸고 ... (스탠드어론) 그래서 중간에 서비스 중단 발생,, 오토스케일링은 일정규모의인스턴스 개수 유지 설정 해놓으면 조건이 되었을때 생성규칙을 정의(런치 컨피규레이션 생성) 
- 어제 다섯번째(rdb database): vpc 안에 서브넷 두개 만든다 (외부 내부 서브넷) 외부서브넷에 ec2 .. 웹 설정 같은 것들 내부서브넷은 db 등 노출되면 안되는 것 ,,,,가끔 외부 사용자가 내부 디비 설정접근해야할때, 사용자가 외부 서브넷 접속하고 외부에서 내부 서브넷으로 접근 (터널링),, 외부 서브넷 보안그룹이 있음
- ![image-20201008092412534](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20201008092412534.png)



## 오늘

#### 테이블



#### **Creating and Subscribing to AWS SNS Topics**

- 사용자에게 이메일 전달하거나 이벤트를 해주거나..
- 주제(topic)
- 구독(subscribe) - 이메일, sns, ... lambda
- 메시지 게시: 주제를 구독 형태로 전달
- 서버리스 에서 , 서비스 구현해 높은 서비스 : 람다함수임
- 서버리스 : 컨테이너 기반의 서비스로 구현된 그런것들은 간소화 해주는 
- 람다를 구독자로 추가하기 위해 람다 함수정의해보기



#### Configuring SNS Push Notifications on S3 Bucket Events Inside of the AWS Console

- ![image-20201008111306804](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20201008111306804.png)

- 사용자가 인터페이스에 파일올리면 s3버킷으로 가고 sns 토픽 정책에 의해 sns 토픽으로
- s3에서 다른 aws 객체로부터 발생한 이벤트를 토픽으로 연결하는 것에 대해 다룸



- 순서

- sns에서 토픽 생성

- s3에서버킷 생성 -> 버킷 속성에 이벤트(대상 sns 토픽) : s3 호출할 수 없음
- sns 다시가서 , s3events 클릭하여 액세스 정책에 코드추가(s3버킷의 시그널이 오면 sns 이벤트 퍼블리싱(게시) ) 
- s3다시가서, 이벤트 생성 권한 주기



- 비동기 방식으로 처리 할 때 요청처리가 정확히  어떤 상태로 진행되어서 어떻게 끝나는가 중요
- 내 어플리케이션 에서 문자 발송 하고 싶어,, 직접 하는 것보다 메시지 큐에 던져 놓으면 중간역할 하는게 주고 받음
- 메시지의 정확한 처리 역할 : 메시지 큐
- 메시지 큐에 데이터 집어넣기: 프로바이저? 공급자  //반대: 소비자
- 

#### **Working with AWS SQS Standard Queues**

- SQS : AWS에서 가장 먼저 생긴 리소스
- 메시지(MESSAGE) 
  - XML, JSON 과 같은 형태르 가진 데이터
  - 256KB
  - 유니코드 사용이 가능
- 큐(QUEUE)
  - 메시지 담는 공간
  - 리전 별로 생성해야 함
  - 큐 이름은 모든 리전에서 유일해야  함

- 배치 API
  - 용량이 작은 메시지를 자주 처리하면, 과금 발생하므로
  - 메시지를 모아서 동시에 처리

- Visibility Timeout
  - 메시지 받은 뒤 특정 시간 동안 다른 곳에서 메시지 볼 수 없도록 하는 기능
  - 여러 서버가 메시지를 처리하는 경우, 동일한 메시지를 동시에 (중복해서) 처리하는 것을 방지
    - Message Available => Visible => 메시지를 꺼내 볼 수 있는 상태
    - Message in Fight => Not Visible => 다른 곳에서 메시지를 보고 있어 볼 수 없는 메시지
    - 나 멋지다

- Delay Delivery
  - 나 진짜 졸려 ㅔㅈ발 쉬자고요
  - 특정 시간 동안 메시지를 받지 못하게 하는 기능
  - Message in Fight 상태

- Dead Letter Queues
  - 일반적으로 메시지 받아서 처리하면 메시지 삭제
  - 삭제되지 않고 남아있는 경우에는 처리 실패 큐(Dead Letter Queue)로 보냄
  - 일반 큐와 동일한 리전에 있어야 함

- Long Polling
  - 메시지가 있으면 바로 가져오고 없으면 올 때 까지 기다림
  - 기본 20 초, 1~20초까지 설정 가능

- Short Polling
  - 메시지가 있으면 바로 가져오고 없으면 빠져 나옴
  - ReceiveMessage 요청에서 WaitTimeSeconds 를 0으로 설정
  - 큐 설정에서 ReceiveMessageWaitTimeSeconds 를 0으로 설정

![image-20201008142416528](C:\Users\i\AppData\Roaming\Typora\typora-user-images\image-20201008142416528.png)

#### **Working with AWS SQS Standard Queues**

~~~
you will learn how to create and interact with SQS standard queues. You will send messages to an SQS queue that you create, and learn how to take advantage of SQS queues to use multiple SQS consumers to process queue data at the same time! By the end of this AWS learning activity, you should feel comfortable interacting with the SQS service via the Boto3 SDK for Python. You will also gain an understanding of how to send messages to standard queues, set queue attributes, and consume messages from the queues we create.
~~~

**https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sqs.html**



- Boto3 SDK이용해서 파이썬 프로그램을 제공

- SSH 터미널을 5개 실행해서 

  ~~~~
  ApproximateNumberOfMessagesNotVisible	⇐ 메시지 못받음
  ApproximateNumberOfMessages  <= 메시지 개수
  ApproximateNumberOfMessagesDelayed
  
  홈디렉터리에 있는 py 파일의 내용을 이해
  ~~~~

- 소스

  ~~~~
  create_queue.py
  import boto3
  
  # Create SQS client
  sqs = boto3.client('sqs')
  
  # Create a SQS queue
  # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sqs.html#SQS.Client.create_queue
  response = sqs.create_queue(
      QueueName='mynewq',
      Attributes={
          'DelaySeconds': '5', # 5초만 멈춰
          'MessageRetentionPeriod': '86400' # 24시간
      }
  )
  
  print(response['QueueUrl']) #sqs_url에 접근할수있는 유아이주소
  
  
  queue_status.py # 1초단위로아래작업수행 100000번
  import boto3
  import time
  from sqs_url import QUEUE_URL
  
  sqs = boto3.client('sqs')
  
  i = 0
  
  while i < 100000:
      i = i + 1
      time.sleep(1) 
      response = sqs.get_queue_attributes(
          QueueUrl=QUEUE_URL,
          AttributeNames=[
              'ApproximateNumberOfMessages',
              'ApproximateNumberOfMessagesNotVisible',
              'ApproximateNumberOfMessagesDelayed',
          ]
      )
      for attribute in response['Attributes']:
          print(
              response['Attributes'][attribute] +
              ' ' +
              attribute
          )
      print('')
      print('')
      print('')
      print('')
  
  
  ApproximateNumberOfMessages – Returns the approximate number of messages available for retrieval from the queue.
  ApproximateNumberOfMessagesDelayed – Returns the approximate number of messages in the queue that are delayed and not available for reading immediately. This can happen when the queue is configured as a delay queue or when a message has been sent with a delay parameter.
  ApproximateNumberOfMessagesNotVisible – Returns the approximate number of messages that are in flight. Messages are considered to be in flight if they have been sent to a client but have not yet been deleted or have not yet reached the end of their visibility window.
  
  slow_producer.py
  import boto3
  import json
  import time
  from sqs_url import QUEUE_URL
  
  # Create SQS client
  sqs = boto3.client('sqs')
  
  with open('slow_data.json', 'r') as f:
      data = json.loads(f.read())
  
  for i in data:
      msg_body = json.dumps(i)
      response = sqs.send_message(
          QueueUrl=QUEUE_URL,
          MessageBody=msg_body,
          DelaySeconds=10,
          MessageAttributes={
              'JobType': {
                  'DataType': 'String',
                  'StringValue': 'NewDonor'
              },
              'Producer': {
                  'DataType': 'String',
                  'StringValue': 'Slow'
              }
          }
      )
      print('Added a message with 10 second delay - SLOW')
      print(response)
      time.sleep(1)
  
  
  fast_producer.py
  import boto3
  import json
  import time
  from sqs_url import QUEUE_URL
  
  # Create SQS client
  sqs = boto3.client('sqs')
  
  with open('fast_data.json', 'r') as f:
      data = json.loads(f.read())
  
  for i in data:
      msg_body = json.dumps(i)
      response = sqs.send_message(
          QueueUrl=QUEUE_URL,
          MessageBody=msg_body,
          DelaySeconds=2,
          MessageAttributes={
              'JobType': {
                  'DataType': 'String',
                  'StringValue': 'NewDonor'
              },
              'Producer': {
                  'DataType': 'String',
                  'StringValue': 'Fast'
              }
          }
      )
      print('Added a message with 1 second delay - FAST')
      print(response)
      time.sleep(1)
  
  
  slow_consumer.py
  import boto3
  import json
  import time
  from sqs_url import QUEUE_URL
  
  # Create SQS client
  sqs = boto3.client('sqs')
  
  i = 0
  
  while i < 10000:
      i = i + 1
      rec_res = sqs.receive_message(
          QueueUrl=QUEUE_URL,
          MessageAttributeNames=[
              'All',
          ],
          MaxNumberOfMessages=1,
          VisibilityTimeout=20,
          WaitTimeSeconds=10
      )
      del_res = sqs.delete_message(
          QueueUrl=QUEUE_URL,
          ReceiptHandle=rec_res['Messages'][0]['ReceiptHandle']
      )
      print("RECIEVED MESSAGE (SLOW CONSUMER):")
      print('FROM PRODUCER: ' + rec_res['Messages'][0]['MessageAttributes']['Producer']['StringValue'])
      print('JOB TYPE: ' + rec_res['Messages'][0]['MessageAttributes']['JobType']['StringValue'])
      print('BODY: ' + rec_res['Messages'][0]['Body'])
      print("DELETED MESSAGE (SLOW CONSUMER)")
      print("")
      time.sleep(8)
  # notvisible한것이 1초마다 쌓이고, 20개를 넘기지 않는다
  # 1,2,3,...20, 1,2,...
  # 
  
  fast_consumer.py
  import boto3
  import json
  import time
  from sqs_url import QUEUE_URL
  
  # Create SQS client
  sqs = boto3.client('sqs')
  
  i = 0
  
  while i < 10000:
      i = i + 1
      rec_res = sqs.receive_message(
          QueueUrl=QUEUE_URL,
          MessageAttributeNames=[
              'All',
          ],
          MaxNumberOfMessages=1,
          VisibilityTimeout=5,
          WaitTimeSeconds=10
      )
      del_res = sqs.delete_message(
          QueueUrl=QUEUE_URL,
          ReceiptHandle=rec_res['Messages'][0]['ReceiptHandle']
      )
      print("RECIEVED MESSAGE (FAST CONSUMER):")
      print('FROM PRODUCER: ' + rec_res['Messages'][0]['MessageAttributes']['Producer']['StringValue'])
      print('JOB TYPE: ' + rec_res['Messages'][0]['MessageAttributes']['JobType']['StringValue'])
      print('BODY: ' + rec_res['Messages'][0]['Body'])
      print("DELETED MESSAGE (FAST CONSUMER)")
      print("")
      time.sleep(2)
  
  ~~~~

  - slow_producer : 메시지 1초마다 띄우고 있고,   messages로 간다?
  - waittimeseconds : 
  - 지금하는ㄱ ㅓ 너무 집주중 안된다
  - 

